{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 523 files in total.\n",
      "Number of files with potential transcription looping: 6\n",
      "\n",
      "Files with potential transcription looping:\n",
      "- 00028_11.txt\n",
      "- 00031_2.txt\n",
      "- 00040_3.txt\n",
      "- 00063_1.txt\n",
      "- 00067_7.txt\n",
      "- 00087_3.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def check_transcription_looping(file_path, check_words=20, min_repeat_length=10, repeat_threshold=0.7):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    words = content.split()\n",
    "    if len(words) < check_words * 2:\n",
    "        return False  # File is too short for meaningful check\n",
    "\n",
    "    # Check the last 'check_words' against the preceding text\n",
    "    end_words = words[-check_words:]\n",
    "    preceding_text = ' '.join(words[:-check_words])\n",
    "\n",
    "    for i in range(len(end_words) - min_repeat_length + 1):\n",
    "        phrase = ' '.join(end_words[i:i+min_repeat_length])\n",
    "        if phrase in preceding_text:\n",
    "            # Found a repeating phrase, now check for extended repetition\n",
    "            extended_phrase = ' '.join(end_words[i:])\n",
    "            matches = sum(1 for word in extended_phrase.split() if word in preceding_text.split()[-len(extended_phrase.split()):])\n",
    "            if matches / len(extended_phrase.split()) >= repeat_threshold:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    looping_files = []\n",
    "    total_files = 0\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            total_files += 1\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                if check_transcription_looping(file_path):\n",
    "                    looping_files.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    return looping_files, total_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'transcriptions_BG_internVL/txt/'\n",
    "looping_files, total_files = process_folder(folder_path)\n",
    "\n",
    "print(f\"Processed {total_files} files in total.\")\n",
    "print(f\"Number of files with potential transcription looping: {len(looping_files)}\")\n",
    "\n",
    "if looping_files:\n",
    "    print(\"\\nFiles with potential transcription looping:\")\n",
    "    for file in looping_files:\n",
    "        print(f\"- {file}\")\n",
    "else:\n",
    "    print(\"No transcription looping detected in any files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: transcriptions_BG_minicpm/html\\32044150449080_009.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449080_014.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449080_021.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449098_001.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449098_006.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449098_017.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449098_021.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449098_022.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449106_008.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449106_021.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449106_027.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449106_033.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_007.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_009.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_031.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_037.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_042.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_048.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_049.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_063.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_076.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_082.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449114_085.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_005.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_011.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_020.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_023.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_028.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449122_039.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_003.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_004.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_006.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_017.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_030.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_036.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449130_041.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_009.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_016.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_017.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_023.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_035.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_037.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_040.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_046.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_055.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_059.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449148_070.html\n",
      "Deleted: transcriptions_BG_minicpm/html\\32044150449155_010.html\n",
      "Operation completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the folder containing the files\n",
    "folder_path = 'transcriptions_BG_minicpm/html'  # Change this to your folder path\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "all_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "# Sort the files to ensure a consistent order (optional)\n",
    "all_files.sort()\n",
    "\n",
    "# Check the number of files\n",
    "num_files = len(all_files)\n",
    "\n",
    "# If there are more than 500 files, delete the extra ones\n",
    "if num_files > 500:\n",
    "    files_to_delete = all_files[500:]  # Get files beyond the first 500\n",
    "    for file in files_to_delete:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        os.remove(file_path)  # Delete the file\n",
    "        print(f\"Deleted: {file_path}\")\n",
    "else:\n",
    "    print(f\"There are only {num_files} files. No files deleted.\")\n",
    "\n",
    "print(\"Operation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 523 files in total.\n",
      "Number of files with potential transcription looping: 52\n",
      "\n",
      "Files with potential transcription looping:\n",
      "- 00004_3.txt\n",
      "- 00004_5.txt\n",
      "- 00005_1.txt\n",
      "- 00006_3.txt\n",
      "- 00009_5.txt\n",
      "- 00012_15.txt\n",
      "- 00016_1.txt\n",
      "- 00017_7.txt\n",
      "- 00021_5.txt\n",
      "- 00022_1.txt\n",
      "- 00026_3.txt\n",
      "- 00030_5.txt\n",
      "- 00033_5.txt\n",
      "- 00036_1.txt\n",
      "- 00042_5.txt\n",
      "- 00046_1.txt\n",
      "- 00046_3.txt\n",
      "- 00046_7.txt\n",
      "- 00048_12.txt\n",
      "- 00052_4.txt\n",
      "- 00054_1.txt\n",
      "- 00063_1.txt\n",
      "- 00066_11.txt\n",
      "- 00066_3.txt\n",
      "- 00067_11.txt\n",
      "- 00069_1.txt\n",
      "- 00070_7.txt\n",
      "- 00071_7.txt\n",
      "- 00072_3.txt\n",
      "- 00074_7.txt\n",
      "- 00075_7.txt\n",
      "- 00076_11.txt\n",
      "- 00076_17.txt\n",
      "- 00076_19.txt\n",
      "- 00079_6.txt\n",
      "- 00082_13.txt\n",
      "- 00082_6.txt\n",
      "- 00084_1.txt\n",
      "- 00085_1.txt\n",
      "- 00085_9.txt\n",
      "- 00087_1.txt\n",
      "- 00090_4.txt\n",
      "- 00091_3.txt\n",
      "- 00091_8.txt\n",
      "- 00092_1.txt\n",
      "- 00092_3.txt\n",
      "- 00093_1.txt\n",
      "- 00093_13.txt\n",
      "- 00093_6.txt\n",
      "- 00097_19.txt\n",
      "- 00098_3.txt\n",
      "- 00100_7.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def check_transcription_looping(file_path, check_words=20, min_repeat_length=10, repeat_threshold=0.7):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read().strip()\n",
    "\n",
    "    words = content.split()\n",
    "    if len(words) < check_words * 2:\n",
    "        return False  # File is too short for meaningful check\n",
    "\n",
    "    # Check the last 'check_words' against the preceding text\n",
    "    end_words = words[-check_words:]\n",
    "    preceding_text = ' '.join(words[:-check_words])\n",
    "\n",
    "    for i in range(len(end_words) - min_repeat_length + 1):\n",
    "        phrase = ' '.join(end_words[i:i+min_repeat_length])\n",
    "        if phrase in preceding_text:\n",
    "            # Found a repeating phrase, now check for extended repetition\n",
    "            extended_phrase = ' '.join(end_words[i:])\n",
    "            matches = sum(1 for word in extended_phrase.split() if word in preceding_text.split()[-len(extended_phrase.split()):])\n",
    "            if matches / len(extended_phrase.split()) >= repeat_threshold:\n",
    "                return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    looping_files = []\n",
    "    total_files = 0\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            total_files += 1\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                if check_transcription_looping(file_path):\n",
    "                    looping_files.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {str(e)}\")\n",
    "    \n",
    "    return looping_files, total_files\n",
    "\n",
    "# Example usage\n",
    "folder_path = 'transcriptions_BG_minicpm/txt/'\n",
    "looping_files, total_files = process_folder(folder_path)\n",
    "\n",
    "print(f\"Processed {total_files} files in total.\")\n",
    "print(f\"Number of files with potential transcription looping: {len(looping_files)}\")\n",
    "\n",
    "if looping_files:\n",
    "    print(\"\\nFiles with potential transcription looping:\")\n",
    "    for file in looping_files:\n",
    "        print(f\"- {file}\")\n",
    "else:\n",
    "    print(\"No transcription looping detected in any files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File containing the phrase: 00090_9.txt\n",
      "\n",
      "Total files with the phrase: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'transcriptions_BG_minicpm/txt/'\n",
    "counter = 0\n",
    "\n",
    "# Iterate over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if the path is a file (not a folder)\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file content\n",
    "        with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Check if the phrase is in the content\n",
    "        if \" can't assist \" in content:\n",
    "            counter += 1\n",
    "            print(f'File containing the phrase: {filename}')\n",
    "\n",
    "print(f'\\nTotal files with the phrase: {counter}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total files with the phrase: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'BGdataset/transcriptions_BG_molmo/txt/'\n",
    "counter = 0\n",
    "\n",
    "# Iterate over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if the path is a file (not a folder)\n",
    "    if os.path.isfile(file_path):\n",
    "        # Open and read the file content\n",
    "        with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Check if the phrase is in the content\n",
    "        if \"can't assist\" in content:\n",
    "            counter += 1\n",
    "            print(f'File containing the phrase: {filename}')\n",
    "\n",
    "print(f'\\nTotal files with the phrase: {counter}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
