{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: 00003_1.txt\n",
      "WER: 0.9518\n",
      "CER: 0.7629\n",
      "Edit Distance: 298.0000\n",
      "--------------------\n",
      "File 2: 00003_3.txt\n",
      "WER: 0.5437\n",
      "CER: 0.3476\n",
      "Edit Distance: 171.0000\n",
      "--------------------\n",
      "File 3: 00004_1.txt\n",
      "WER: 0.9786\n",
      "CER: 0.7624\n",
      "Edit Distance: 545.0000\n",
      "--------------------\n",
      "File 4: 00010_7.txt\n",
      "WER: 0.9521\n",
      "CER: 0.7905\n",
      "Edit Distance: 547.0000\n",
      "--------------------\n",
      "File 5: 00012_13.txt\n",
      "WER: 0.9664\n",
      "CER: 0.7595\n",
      "Edit Distance: 529.0000\n",
      "--------------------\n",
      "File 6: 00019_15.txt\n",
      "WER: 0.6275\n",
      "CER: 0.4875\n",
      "Edit Distance: 138.0000\n",
      "--------------------\n",
      "File 7: 00021_7.txt\n",
      "WER: 0.9508\n",
      "CER: 0.7578\n",
      "Edit Distance: 502.0000\n",
      "--------------------\n",
      "File 8: 00028_1.txt\n",
      "WER: 0.9521\n",
      "CER: 0.7811\n",
      "Edit Distance: 598.0000\n",
      "--------------------\n",
      "File 9: 00029_11.txt\n",
      "WER: 0.9558\n",
      "CER: 0.7653\n",
      "Edit Distance: 637.0000\n",
      "--------------------\n",
      "File 10: 00029_9.txt\n",
      "WER: 0.9542\n",
      "CER: 0.8011\n",
      "Edit Distance: 591.0000\n",
      "--------------------\n",
      "File 11: 00030_1.txt\n",
      "WER: 0.9700\n",
      "CER: 0.8381\n",
      "Edit Distance: 410.0000\n",
      "--------------------\n",
      "File 12: 00031_2.txt\n",
      "WER: 0.5082\n",
      "CER: 0.2562\n",
      "Edit Distance: 154.0000\n",
      "--------------------\n",
      "File 13: 00033_11.txt\n",
      "WER: 0.9147\n",
      "CER: 0.7795\n",
      "Edit Distance: 1038.0000\n",
      "--------------------\n",
      "File 14: 00033_9.txt\n",
      "WER: 0.9850\n",
      "CER: 0.7847\n",
      "Edit Distance: 1014.0000\n",
      "--------------------\n",
      "File 15: 00034_1.txt\n",
      "WER: 0.9944\n",
      "CER: 0.8201\n",
      "Edit Distance: 702.0000\n",
      "--------------------\n",
      "File 16: 00043_13.txt\n",
      "WER: 0.8113\n",
      "CER: 0.6935\n",
      "Edit Distance: 172.0000\n",
      "--------------------\n",
      "File 17: 00044_1.txt\n",
      "WER: 0.9615\n",
      "CER: 0.7982\n",
      "Edit Distance: 627.0000\n",
      "--------------------\n",
      "File 18: 00048_13.txt\n",
      "WER: 1.0333\n",
      "CER: 0.9430\n",
      "Edit Distance: 281.0000\n",
      "--------------------\n",
      "File 19: 00048_15.txt\n",
      "WER: 0.6562\n",
      "CER: 0.4060\n",
      "Edit Distance: 136.0000\n",
      "--------------------\n",
      "File 20: 00048_19.txt\n",
      "WER: 0.5227\n",
      "CER: 0.3886\n",
      "Edit Distance: 75.0000\n",
      "--------------------\n",
      "File 21: 00048_4.txt\n",
      "WER: 0.7586\n",
      "CER: 0.5088\n",
      "Edit Distance: 144.0000\n",
      "--------------------\n",
      "File 22: 00048_7.txt\n",
      "WER: 1.0000\n",
      "CER: 0.7994\n",
      "Edit Distance: 267.0000\n",
      "--------------------\n",
      "File 23: 00050_2.txt\n",
      "WER: 0.4524\n",
      "CER: 0.2644\n",
      "Edit Distance: 101.0000\n",
      "--------------------\n",
      "File 24: 00051_4.txt\n",
      "WER: 0.5750\n",
      "CER: 0.4674\n",
      "Edit Distance: 179.0000\n",
      "--------------------\n",
      "File 25: 00052_7.txt\n",
      "WER: 0.8070\n",
      "CER: 0.6535\n",
      "Edit Distance: 198.0000\n",
      "--------------------\n",
      "File 26: 00052_9.txt\n",
      "WER: 0.7470\n",
      "CER: 0.5340\n",
      "Edit Distance: 290.0000\n",
      "--------------------\n",
      "File 27: 00056_7.txt\n",
      "WER: 1.0000\n",
      "CER: 0.7926\n",
      "Edit Distance: 685.0000\n",
      "--------------------\n",
      "File 28: 00056_9.txt\n",
      "WER: 0.9842\n",
      "CER: 0.8110\n",
      "Edit Distance: 794.0000\n",
      "--------------------\n",
      "File 29: 00058_5.txt\n",
      "WER: 0.5155\n",
      "CER: 0.3185\n",
      "Edit Distance: 143.0000\n",
      "--------------------\n",
      "File 30: 00067_15.txt\n",
      "WER: 0.9583\n",
      "CER: 0.7919\n",
      "Edit Distance: 430.0000\n",
      "--------------------\n",
      "File 31: 00071_5.txt\n",
      "WER: 0.9626\n",
      "CER: 0.8129\n",
      "Edit Distance: 404.0000\n",
      "--------------------\n",
      "File 32: 00076_15.txt\n",
      "WER: 0.9519\n",
      "CER: 0.8091\n",
      "Edit Distance: 407.0000\n",
      "--------------------\n",
      "File 33: 00079_3.txt\n",
      "WER: 0.4737\n",
      "CER: 0.2696\n",
      "Edit Distance: 155.0000\n",
      "--------------------\n",
      "File 34: 00079_5.txt\n",
      "WER: 0.9562\n",
      "CER: 0.7602\n",
      "Edit Distance: 547.0000\n",
      "--------------------\n",
      "File 35: 00082_3.txt\n",
      "WER: 0.4135\n",
      "CER: 0.1818\n",
      "Edit Distance: 122.0000\n",
      "--------------------\n",
      "File 36: 00084_11.txt\n",
      "WER: 0.9450\n",
      "CER: 0.7704\n",
      "Edit Distance: 810.0000\n",
      "--------------------\n",
      "File 37: 00085_3.txt\n",
      "WER: 0.4444\n",
      "CER: 0.3241\n",
      "Edit Distance: 198.0000\n",
      "--------------------\n",
      "File 38: 00085_4.txt\n",
      "WER: 0.9554\n",
      "CER: 0.7922\n",
      "Edit Distance: 558.0000\n",
      "--------------------\n",
      "File 39: 00090_10.txt\n",
      "WER: 1.0140\n",
      "CER: 0.8151\n",
      "Edit Distance: 600.0000\n",
      "--------------------\n",
      "File 40: 00091_1.txt\n",
      "WER: 0.7436\n",
      "CER: 0.5308\n",
      "Edit Distance: 112.0000\n",
      "--------------------\n",
      "File 41: 00093_1.txt\n",
      "WER: 0.9863\n",
      "CER: 0.8100\n",
      "Edit Distance: 857.0000\n",
      "--------------------\n",
      "File 42: 00093_13.txt\n",
      "WER: 0.9771\n",
      "CER: 0.8052\n",
      "Edit Distance: 1139.0000\n",
      "--------------------\n",
      "File 43: 00094_1.txt\n",
      "WER: 0.9348\n",
      "CER: 0.6448\n",
      "Edit Distance: 233.0000\n",
      "--------------------\n",
      "File 44: 00096_3.txt\n",
      "WER: 0.9877\n",
      "CER: 0.7772\n",
      "Edit Distance: 300.0000\n",
      "--------------------\n",
      "File 45: 00097_23.txt\n",
      "WER: 0.9892\n",
      "CER: 0.8004\n",
      "Edit Distance: 722.0000\n",
      "--------------------\n",
      "File 46: 00097_9.txt\n",
      "WER: 0.9533\n",
      "CER: 0.7865\n",
      "Edit Distance: 608.0000\n",
      "--------------------\n",
      "File 47: 00098_3.txt\n",
      "WER: 0.5960\n",
      "CER: 0.3783\n",
      "Edit Distance: 185.0000\n",
      "--------------------\n",
      "\n",
      "Overall Results:\n",
      "Average WER: 0.8356\n",
      "Average CER: 0.6539\n",
      "Average Edit Distance: 433.0425\n",
      "Total files processed: 47\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchmetrics.text import CharErrorRate, EditDistance, WordErrorRate\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "def evaluate_transcriptions(pred_folder, target_folder, file_limit=529):\n",
    "    cer = CharErrorRate()\n",
    "    wer = WordErrorRate()\n",
    "    edit_distance = EditDistance()\n",
    "\n",
    "    total_cer = 0\n",
    "    total_wer = 0\n",
    "    total_edit_distance = 0\n",
    "    file_count = 0\n",
    "\n",
    "    # Get lists of files from both folders\n",
    "    pred_files = sorted([f for f in os.listdir(pred_folder) if f.endswith('.txt')])\n",
    "    target_files = sorted([f for f in os.listdir(target_folder) if f.endswith('.txt')])\n",
    "\n",
    "    for pred_filename in pred_files[:file_limit]:\n",
    "        pred_id = os.path.splitext(pred_filename)[0]  # Get the ID before .txt\n",
    "        \n",
    "        # Check if there's a corresponding file in the target folder with the same ID\n",
    "        matching_target_file = next((f for f in target_files if os.path.splitext(f)[0] == pred_id), None)\n",
    "\n",
    "        if matching_target_file:\n",
    "            pred_path = os.path.join(pred_folder, pred_filename)\n",
    "            target_path = os.path.join(target_folder, matching_target_file)\n",
    "\n",
    "            pred_text = read_file(pred_path)\n",
    "            target_text = read_file(target_path)\n",
    "\n",
    "            file_cer = cer([pred_text], [target_text])\n",
    "            file_wer = wer([pred_text], [target_text])\n",
    "            file_edit_distance = edit_distance([pred_text], [target_text])\n",
    "\n",
    "            total_cer += file_cer\n",
    "            total_wer += file_wer\n",
    "            total_edit_distance += file_edit_distance\n",
    "            file_count += 1\n",
    "\n",
    "            print(f\"File {file_count}: {pred_filename}\")\n",
    "            print(f\"WER: {file_wer:.4f}\")\n",
    "            print(f\"CER: {file_cer:.4f}\")\n",
    "            print(f\"Edit Distance: {file_edit_distance:.4f}\")\n",
    "            print(\"--------------------\")\n",
    "\n",
    "        if file_count >= file_limit:\n",
    "            break\n",
    "\n",
    "    if file_count > 0:\n",
    "        avg_cer = total_cer / file_count\n",
    "        avg_wer = total_wer / file_count\n",
    "        avg_edit_distance = total_edit_distance / file_count\n",
    "\n",
    "        print(\"\\nOverall Results:\")\n",
    "        print(f\"Average WER: {avg_wer:.4f}\")\n",
    "        print(f\"Average CER: {avg_cer:.4f}\")\n",
    "        print(f\"Average Edit Distance: {avg_edit_distance:.4f}\")\n",
    "        print(f\"Total files processed: {file_count}\")\n",
    "    else:\n",
    "        print(\"No matching files found.\")\n",
    "\n",
    "# Example usage\n",
    "pred_folder = 'BGdataset/transkribus_transcription'\n",
    "target_folder = 'BGdataset/filtered100txt'\n",
    "evaluate_transcriptions(pred_folder, target_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c04-160.txt - CER: 3.76%\n",
      "e01-018.txt - CER: 9.57%\n",
      "m04-019.txt - CER: 7.87%\n",
      "n06-182.txt - CER: 7.76%\n",
      "g04-036.txt - CER: 9.61%\n",
      "n02-098.txt - CER: 12.50%\n",
      "n04-195.txt - CER: 2.82%\n",
      "p03-185.txt - CER: 3.85%\n",
      "n06-148.txt - CER: 6.98%\n",
      "m02-052.txt - CER: 2.73%\n",
      "n06-186.txt - CER: 9.61%\n",
      "m04-190.txt - CER: 2.94%\n",
      "m04-164.txt - CER: 4.80%\n",
      "m01-090.txt - CER: 5.01%\n",
      "d01-024.txt - CER: 7.23%\n",
      "p03-103.txt - CER: 11.01%\n",
      "f04-049.txt - CER: 3.14%\n",
      "n03-082.txt - CER: 4.50%\n",
      "m04-209.txt - CER: 3.06%\n",
      "e06-006.txt - CER: 3.56%\n",
      "m04-024.txt - CER: 5.08%\n",
      "p03-057.txt - CER: 9.89%\n",
      "d04-117.txt - CER: 3.94%\n",
      "p03-121.txt - CER: 5.45%\n",
      "n02-000.txt - CER: 3.48%\n",
      "n04-190.txt - CER: 3.42%\n",
      "m06-019.txt - CER: 4.22%\n",
      "m04-222.txt - CER: 4.37%\n",
      "d01-056.txt - CER: 3.00%\n",
      "f07-046b.txt - CER: 3.23%\n",
      "n06-163.txt - CER: 7.13%\n",
      "m04-180.txt - CER: 4.46%\n",
      "n06-201.txt - CER: 8.02%\n",
      "m02-090.txt - CER: 4.23%\n",
      "d04-071.txt - CER: 4.21%\n",
      "n02-082a.txt - CER: 6.25%\n",
      "p03-135.txt - CER: 9.69%\n",
      "p03-087.txt - CER: 7.32%\n",
      "d03-112.txt - CER: 40.68%\n",
      "n04-044.txt - CER: 4.07%\n",
      "d04-005.txt - CER: 4.79%\n",
      "n06-169.txt - CER: 8.52%\n",
      "f04-100.txt - CER: 19.46%\n",
      "p03-112.txt - CER: 9.16%\n",
      "g04-055.txt - CER: 3.21%\n",
      "h01-004.txt - CER: 10.56%\n",
      "p02-017.txt - CER: 2.60%\n",
      "p02-131.txt - CER: 2.64%\n",
      "d04-008.txt - CER: 3.68%\n",
      "m02-102.txt - CER: 3.27%\n",
      "p03-009.txt - CER: 3.67%\n",
      "c04-156.txt - CER: 7.14%\n",
      "m04-000.txt - CER: 11.61%\n",
      "d01-060.txt - CER: 33.69%\n",
      "n02-016.txt - CER: 2.80%\n",
      "p02-121.txt - CER: 5.86%\n",
      "m03-095.txt - CER: 3.96%\n",
      "m04-216.txt - CER: 3.51%\n",
      "c06-083.txt - CER: 4.23%\n",
      "p02-127.txt - CER: 2.94%\n",
      "e06-041.txt - CER: 7.10%\n",
      "m04-012.txt - CER: 7.41%\n",
      "f04-046.txt - CER: 2.42%\n",
      "n04-171.txt - CER: 2.70%\n",
      "n06-194.txt - CER: 8.68%\n",
      "f04-096.txt - CER: 29.69%\n",
      "d04-075.txt - CER: 45.66%\n",
      "f07-039b.txt - CER: 3.68%\n",
      "m04-152.txt - CER: 4.56%\n",
      "n04-039.txt - CER: 7.36%\n",
      "m04-251.txt - CER: 3.16%\n",
      "m01-160.txt - CER: 3.20%\n",
      "m01-115.txt - CER: 5.76%\n",
      "n04-015.txt - CER: 4.72%\n",
      "f07-032b.txt - CER: 2.74%\n",
      "m04-200.txt - CER: 5.71%\n",
      "n04-031.txt - CER: 3.03%\n",
      "p03-151.txt - CER: 2.82%\n",
      "g03-016.txt - CER: 2.70%\n",
      "g04-039.txt - CER: 9.92%\n",
      "n03-091.txt - CER: 5.26%\n",
      "e06-037.txt - CER: 3.33%\n",
      "d06-000.txt - CER: 22.52%\n",
      "p03-004.txt - CER: 11.85%\n",
      "f07-028b.txt - CER: 2.24%\n",
      "p03-096.txt - CER: 12.29%\n",
      "d06-091.txt - CER: 7.78%\n",
      "g03-058.txt - CER: 3.50%\n",
      "d06-030.txt - CER: 2.58%\n",
      "n03-079.txt - CER: 4.92%\n",
      "e01-014.txt - CER: 2.15%\n",
      "d04-081.txt - CER: 4.72%\n",
      "p03-142.txt - CER: 9.97%\n",
      "p03-069.txt - CER: 2.62%\n",
      "m02-106.txt - CER: 6.56%\n",
      "n06-156.txt - CER: 3.98%\n",
      "p02-155.txt - CER: 27.08%\n",
      "m04-007.txt - CER: 3.04%\n",
      "n06-175.txt - CER: 4.37%\n",
      "g04-063.txt - CER: 2.77%\n",
      "d06-082.txt - CER: 2.36%\n",
      "f07-042b.txt - CER: 3.25%\n",
      "d04-121.txt - CER: 4.43%\n",
      "m02-083.txt - CER: 2.74%\n",
      "f04-093.txt - CER: 3.05%\n",
      "n04-183.txt - CER: 5.94%\n",
      "m03-062.txt - CER: 5.95%\n",
      "d06-050.txt - CER: 3.66%\n",
      "g04-060.txt - CER: 3.54%\n",
      "f07-036.txt - CER: 3.88%\n",
      "n04-022.txt - CER: 6.25%\n",
      "d06-015.txt - CER: 3.14%\n",
      "m02-075.txt - CER: 3.60%\n",
      "m04-145.txt - CER: 2.42%\n",
      "g01-083.txt - CER: 7.06%\n",
      "p03-158.txt - CER: 4.32%\n",
      "Average CER over the dataset: 6.76%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein_distance(s1: str, s2: str) -> int:\n",
    "    \"\"\"Calculates the Levenshtein distance between two strings.\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "def cer_single(prediction: str, ground_truth: str) -> float:\n",
    "    \"\"\"Calculates the Character Error Rate (CER) between two strings.\"\"\"\n",
    "    # Calculate the Levenshtein distance (edit distance)\n",
    "    edit_distance = levenshtein_distance(prediction, ground_truth)\n",
    "\n",
    "    # CER = edit distance / number of characters in the ground truth\n",
    "    return edit_distance / len(ground_truth) if len(ground_truth) > 0 else 0\n",
    "\n",
    "def calculate_cer_over_dataset(predictions_folder: str, ground_truth_folder: str) -> float:\n",
    "    \"\"\"Calculates the average CER over a dataset of transcriptions.\"\"\"\n",
    "    cer_scores = []\n",
    "\n",
    "    # Ensure both folders exist\n",
    "    if not os.path.exists(predictions_folder) or not os.path.exists(ground_truth_folder):\n",
    "        raise ValueError(\"Predictions or Ground Truth folder does not exist.\")\n",
    "\n",
    "    # List of files in both folders (assuming .txt files)\n",
    "    prediction_files = [f for f in os.listdir(predictions_folder) if f.endswith('.txt')]\n",
    "    ground_truth_files = [f for f in os.listdir(ground_truth_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Ensure both folders contain the same files\n",
    "    common_files = set(prediction_files).intersection(set(ground_truth_files))\n",
    "\n",
    "    for file_name in common_files:\n",
    "        pred_file_path = os.path.join(predictions_folder, file_name)\n",
    "        gt_file_path = os.path.join(ground_truth_folder, file_name)\n",
    "\n",
    "        # Read the predicted and ground truth transcriptions\n",
    "        with open(pred_file_path, 'r', encoding='utf-8') as pred_file:\n",
    "            prediction_text = pred_file.read().strip()\n",
    "\n",
    "        with open(gt_file_path, 'r', encoding='utf-8') as gt_file:\n",
    "            ground_truth_text = gt_file.read().strip()\n",
    "\n",
    "        # Calculate CER for the current pair and convert it to percentage\n",
    "        cer = cer_single(prediction_text, ground_truth_text) * 100\n",
    "        cer_scores.append(cer)\n",
    "\n",
    "        print(f\"{file_name} - CER: {cer:.2f}%\")\n",
    "\n",
    "    # Return the average CER across the dataset as percentage\n",
    "    return np.mean(cer_scores)\n",
    "\n",
    "# Example usage\n",
    "predictions_folder = \"transcriptions_IAM_gpt4\"  # Path to the folder containing predicted transcriptions\n",
    "ground_truth_folder = \"IAM/aachen_validation_txt\"  # Path to the folder containing ground truth transcriptions\n",
    "\n",
    "average_cer = calculate_cer_over_dataset(predictions_folder, ground_truth_folder)\n",
    "print(f\"Average CER over the dataset: {average_cer:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c04-160.txt - WER: 5.33%\n",
      "e01-018.txt - WER: 7.25%\n",
      "m04-019.txt - WER: 3.57%\n",
      "n06-182.txt - WER: 6.25%\n",
      "g04-036.txt - WER: 9.46%\n",
      "n02-098.txt - WER: 7.41%\n",
      "n04-195.txt - WER: 0.00%\n",
      "p03-185.txt - WER: 7.59%\n",
      "n06-148.txt - WER: 4.11%\n",
      "m02-052.txt - WER: 3.45%\n",
      "n06-186.txt - WER: 8.33%\n",
      "m04-190.txt - WER: 2.56%\n",
      "m04-164.txt - WER: 1.54%\n",
      "m01-090.txt - WER: 1.39%\n",
      "d01-024.txt - WER: 4.92%\n",
      "p03-103.txt - WER: 9.80%\n",
      "f04-049.txt - WER: 3.80%\n",
      "n03-082.txt - WER: 8.77%\n",
      "m04-209.txt - WER: 0.00%\n",
      "e06-006.txt - WER: 0.00%\n",
      "m04-024.txt - WER: 1.72%\n",
      "p03-057.txt - WER: 8.20%\n",
      "d04-117.txt - WER: 7.69%\n",
      "p03-121.txt - WER: 16.13%\n",
      "n02-000.txt - WER: 1.56%\n",
      "n04-190.txt - WER: 3.64%\n",
      "m06-019.txt - WER: 7.94%\n",
      "m04-222.txt - WER: 1.79%\n",
      "d01-056.txt - WER: 6.85%\n",
      "f07-046b.txt - WER: 1.37%\n",
      "n06-163.txt - WER: 5.06%\n",
      "m04-180.txt - WER: 12.50%\n",
      "n06-201.txt - WER: 5.97%\n",
      "m02-090.txt - WER: 7.55%\n",
      "d04-071.txt - WER: 11.86%\n",
      "n02-082a.txt - WER: 18.18%\n",
      "p03-135.txt - WER: 3.17%\n",
      "p03-087.txt - WER: 3.95%\n",
      "d03-112.txt - WER: 34.43%\n",
      "n04-044.txt - WER: 4.60%\n",
      "d04-005.txt - WER: 6.67%\n",
      "n06-169.txt - WER: 10.29%\n",
      "f04-100.txt - WER: 17.86%\n",
      "p03-112.txt - WER: 9.72%\n",
      "g04-055.txt - WER: 2.74%\n",
      "h01-004.txt - WER: 6.90%\n",
      "p02-017.txt - WER: 0.00%\n",
      "p02-131.txt - WER: 0.00%\n",
      "d04-008.txt - WER: 7.41%\n",
      "m02-102.txt - WER: 1.47%\n",
      "p03-009.txt - WER: 8.62%\n",
      "c04-156.txt - WER: 20.41%\n",
      "m04-000.txt - WER: 19.30%\n",
      "d01-060.txt - WER: 36.46%\n",
      "n02-016.txt - WER: 0.00%\n",
      "p02-121.txt - WER: 7.55%\n",
      "m03-095.txt - WER: 3.77%\n",
      "m04-216.txt - WER: 1.85%\n",
      "c06-083.txt - WER: 6.67%\n",
      "p02-127.txt - WER: 0.00%\n",
      "e06-041.txt - WER: 0.00%\n",
      "m04-012.txt - WER: 4.55%\n",
      "f04-046.txt - WER: 0.00%\n",
      "n04-171.txt - WER: 0.00%\n",
      "n06-194.txt - WER: 7.81%\n",
      "f04-096.txt - WER: 26.88%\n",
      "d04-075.txt - WER: 49.26%\n",
      "f07-039b.txt - WER: 1.79%\n",
      "m04-152.txt - WER: 5.26%\n",
      "n04-039.txt - WER: 4.35%\n",
      "m04-251.txt - WER: 0.00%\n",
      "m01-160.txt - WER: 2.13%\n",
      "m01-115.txt - WER: 4.84%\n",
      "n04-015.txt - WER: 2.94%\n",
      "f07-032b.txt - WER: 7.32%\n",
      "m04-200.txt - WER: 8.62%\n",
      "n04-031.txt - WER: 0.00%\n",
      "p03-151.txt - WER: 12.96%\n",
      "g03-016.txt - WER: 0.00%\n",
      "g04-039.txt - WER: 9.59%\n",
      "n03-091.txt - WER: 7.89%\n",
      "e06-037.txt - WER: 0.00%\n",
      "d06-000.txt - WER: 22.68%\n",
      "p03-004.txt - WER: 15.62%\n",
      "f07-028b.txt - WER: 0.00%\n",
      "p03-096.txt - WER: 21.54%\n",
      "d06-091.txt - WER: 4.76%\n",
      "g03-058.txt - WER: 3.45%\n",
      "d06-030.txt - WER: 0.00%\n",
      "n03-079.txt - WER: 11.76%\n",
      "e01-014.txt - WER: 5.00%\n",
      "d04-081.txt - WER: 9.09%\n",
      "p03-142.txt - WER: 24.56%\n",
      "p03-069.txt - WER: 0.00%\n",
      "m02-106.txt - WER: 8.54%\n",
      "n06-156.txt - WER: 9.38%\n",
      "p02-155.txt - WER: 22.22%\n",
      "m04-007.txt - WER: 1.49%\n",
      "n06-175.txt - WER: 10.61%\n",
      "g04-063.txt - WER: 1.02%\n",
      "d06-082.txt - WER: 1.72%\n",
      "f07-042b.txt - WER: 0.00%\n",
      "d04-121.txt - WER: 9.38%\n",
      "m02-083.txt - WER: 1.72%\n",
      "f04-093.txt - WER: 0.00%\n",
      "n04-183.txt - WER: 18.52%\n",
      "m03-062.txt - WER: 10.00%\n",
      "d06-050.txt - WER: 2.86%\n",
      "g04-060.txt - WER: 0.00%\n",
      "f07-036.txt - WER: 3.51%\n",
      "n04-022.txt - WER: 4.69%\n",
      "d06-015.txt - WER: 1.75%\n",
      "m02-075.txt - WER: 0.00%\n",
      "m04-145.txt - WER: 0.00%\n",
      "g01-083.txt - WER: 7.96%\n",
      "p03-158.txt - WER: 10.45%\n",
      "Average WER over the dataset: 7.14%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein_distance(s1: list, s2: list) -> int:\n",
    "    \"\"\"Calculates the Levenshtein distance between two lists of words.\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = list(range(len(s2) + 1))\n",
    "    for i, word1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, word2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (word1 != word2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "\n",
    "def wer_single(prediction: str, ground_truth: str) -> float:\n",
    "    \"\"\"Calculates the Word Error Rate (WER) between two strings.\"\"\"\n",
    "    # Split the strings into words\n",
    "    prediction_words = prediction.split()\n",
    "    ground_truth_words = ground_truth.split()\n",
    "\n",
    "    # Calculate the Levenshtein distance (edit distance) for words\n",
    "    edit_distance = levenshtein_distance(prediction_words, ground_truth_words)\n",
    "\n",
    "    # WER = edit distance / number of words in the ground truth\n",
    "    return edit_distance / len(ground_truth_words) if len(ground_truth_words) > 0 else 0\n",
    "\n",
    "def calculate_wer_over_dataset(predictions_folder: str, ground_truth_folder: str) -> float:\n",
    "    \"\"\"Calculates the average WER over a dataset of transcriptions.\"\"\"\n",
    "    wer_scores = []\n",
    "\n",
    "    # Ensure both folders exist\n",
    "    if not os.path.exists(predictions_folder) or not os.path.exists(ground_truth_folder):\n",
    "        raise ValueError(\"Predictions or Ground Truth folder does not exist.\")\n",
    "\n",
    "    # List of files in both folders (assuming .txt files)\n",
    "    prediction_files = [f for f in os.listdir(predictions_folder) if f.endswith('.txt')]\n",
    "    ground_truth_files = [f for f in os.listdir(ground_truth_folder) if f.endswith('.txt')]\n",
    "\n",
    "    # Ensure both folders contain the same files\n",
    "    common_files = set(prediction_files).intersection(set(ground_truth_files))\n",
    "\n",
    "    for file_name in common_files:\n",
    "        pred_file_path = os.path.join(predictions_folder, file_name)\n",
    "        gt_file_path = os.path.join(ground_truth_folder, file_name)\n",
    "\n",
    "        # Read the predicted and ground truth transcriptions\n",
    "        with open(pred_file_path, 'r', encoding='utf-8') as pred_file:\n",
    "            prediction_text = pred_file.read().strip()\n",
    "\n",
    "        with open(gt_file_path, 'r', encoding='utf-8') as gt_file:\n",
    "            ground_truth_text = gt_file.read().strip()\n",
    "\n",
    "        # Calculate WER for the current pair and convert it to percentage\n",
    "        wer = wer_single(prediction_text, ground_truth_text) * 100\n",
    "        wer_scores.append(wer)\n",
    "\n",
    "        print(f\"{file_name} - WER: {wer:.2f}%\")\n",
    "\n",
    "    # Return the average WER across the dataset as percentage\n",
    "    return np.mean(wer_scores)\n",
    "\n",
    "# Example usage\n",
    "predictions_folder = \"transcriptions_IAM_gpt4\"  \n",
    "ground_truth_folder = \"IAM/aachen_validation_txt\"  \n",
    "\n",
    "average_wer = calculate_wer_over_dataset(predictions_folder, ground_truth_folder)\n",
    "print(f\"Average WER over the dataset: {average_wer:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
