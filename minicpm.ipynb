{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun emits light as a mixture of different colors.  This causes it to appear white or yellowish from our perspective on earth, because all these wavelengths reflect off every part of the atmosphere at about equal rates and so we see that color most prominently.\n",
      "\n",
      "However, not all visible wavelengths are equally well absorbed by molecules in Earth's atmosphere; some like violet light get scattered more effectively than others.  The result is an increased proportion being reflected towards us which makes it look blue to our eyes.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "import base64\n",
    "import os\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def transcribe_image(image_path):\n",
    "    base64_image = encode_image(image_path)\n",
    "    \n",
    "    # First turn: Request plain text transcription\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': [\n",
    "                {\n",
    "                    'type': 'image',\n",
    "                    'image': base64_image\n",
    "                },\n",
    "                {\n",
    "                    'type': 'text',\n",
    "                    'text': \"Please transcribe the handwritten text in this image as plain text. Pay attention to uppercase and lowercase letters, as well as any bold, italic, underlined, or struck-through text. Do not include any HTML formatting at this stage.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = ollama.chat(model='minicpm-v', messages=messages)\n",
    "    text_transcription = response['message']['content']\n",
    "\n",
    "    # Second turn: Request HTML formatting\n",
    "    messages.append({\n",
    "        'role': 'assistant',\n",
    "        'content': text_transcription\n",
    "    })\n",
    "    messages.append({\n",
    "        'role': 'user',\n",
    "        'content': \"Based on the transcription you just provided, create a complete, correctly formatted styled HTML document. Use appropriate HTML tags such as <b>, <i>, <u>, and <s> to represent bold, italic, underlined, and struck-through text respectively. Start the HTML document with <!DOCTYPE html>. Ensure that the HTML structure accurately reflects the layout and formatting of the original handwritten text. Do not use CSS related elements.\"\n",
    "    })\n",
    "\n",
    "    response = ollama.chat(model='minicpm-v', messages=messages)\n",
    "    html_transcription = response['message']['content']\n",
    "\n",
    "    return text_transcription, html_transcription\n",
    "\n",
    "# Example usage\n",
    "image_folder = \"BGdataset/images\"  # Replace with your image folder path\n",
    "output_folder_txt = \"transcriptionsBG_minicpm/txt\"  # Replace with your desired output folder path for text\n",
    "output_folder_html = \"transcriptionsBG_minicpm/html\"  # Replace with your desired output folder path for HTML\n",
    "\n",
    "# Create the output folders if they don't exist\n",
    "os.makedirs(output_folder_txt, exist_ok=True)\n",
    "os.makedirs(output_folder_html, exist_ok=True)\n",
    "\n",
    "# Process all images in the folder\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "        \n",
    "        # Transcribe the image\n",
    "        text_transcription, html_transcription = transcribe_image(image_path)\n",
    "        \n",
    "        # Save the text transcription\n",
    "        txt_output_path = os.path.join(output_folder_txt, f\"{os.path.splitext(filename)[0]}_transcription.txt\")\n",
    "        with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text_transcription)\n",
    "        \n",
    "        # Save the HTML transcription\n",
    "        html_output_path = os.path.join(output_folder_html, f\"{os.path.splitext(filename)[0]}_transcription.html\")\n",
    "        with open(html_output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(html_transcription)\n",
    "        \n",
    "        print(f\"Transcriptions for {filename} saved to {txt_output_path} and {html_output_path}\")\n",
    "\n",
    "print(\"All images have been processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
